# import pandas as pd
# import numpy as np
# import os
# import json
# import joblib
# import shap
# import lightgbm as lgb
# import matplotlib.pyplot as plt
# from datetime import datetime
# from sklearn.preprocessing import OneHotEncoder
# from sklearn.compose import ColumnTransformer
# from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
# from sklearn.metrics import average_precision_score, confusion_matrix, roc_auc_score
# from sklearn.pipeline import Pipeline
# # ----------------------------------------------------------------------
# # 0. ×”×’×“×¨×•×ª ×•×§×‘×•×¢×™×
# # ----------------------------------------------------------------------

# OUT_DIR = 'out'
# os.makedirs(OUT_DIR, exist_ok=True)

# # ×ª××¨×™×›×™× ×œ×¤×™×¦×•×œ ×–×× ×™
# TRAIN_END_DATE = datetime(2023, 9, 1) # ×¢×“ ×¡×¤×˜××‘×¨ (×œ× ×›×•×œ×œ)
# VALIDATION_END_DATE = datetime(2023, 10, 1) # ×¡×¤×˜××‘×¨ ×¢×‘×•×¨ Validation, ××•×§×˜×•×‘×¨ ×•×”×œ××” ×œ-Test
# SEED = 42 # ×“×˜×¨××™× ×™×–×

# # ----------------------------------------------------------------------
# # 1. ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ×œ×—×™×©×•×‘ ××˜×¨×™×§×•×ª
# # ----------------------------------------------------------------------

# def calculate_precision_at_k(y_true, y_probas, k_percent):
#     """
#     ××—×©×‘ Precision@k (×”×™×¢×™×œ×•×ª ×‘-k% ×”××“×•×¨×’×™× ×¨××©×•× ×™×).
#     """
#     k = int(len(y_probas) * k_percent / 100)
#     if k == 0:
#         return 0.0

#     df = pd.DataFrame({'proba': y_probas, 'target': y_true})
#     df_sorted = df.sort_values(by='proba', ascending=False)
    
#     top_k = df_sorted.head(k)
    
#     precision = top_k['target'].mean()
    
#     return precision

# # ----------------------------------------------------------------------
# # 2. ×¤×™×¦×•×œ ×–×× ×™ ×•×¢×™×‘×•×“ ××§×“×™×
# # ----------------------------------------------------------------------

# def perform_temporal_split_and_prep(df_final: pd.DataFrame):
#     """
#     ××‘×¦×¢ ×¤×™×¦×•×œ ×–×× ×™ ××—××™×¨ ×œ-Train, Validation ×•-Test
#     ×•××›×™×Ÿ ××ª ×”× ×ª×•× ×™× ×œ××™××•×Ÿ ×”××•×“×œ.
#     """
    
#     # 2.1 ×¤×™×¦×•×œ ×–×× ×™ (×“×¨×™×©×” 2: Temporal Integrity)
#     df_train = df_final[df_final['date'] < TRAIN_END_DATE].copy()
#     df_val_test = df_final[df_final['date'] >= TRAIN_END_DATE].copy()
#     df_val = df_val_test[df_val_test['date'] < VALIDATION_END_DATE].copy()
#     df_test_raw = df_val_test[df_val_test['date'] >= VALIDATION_END_DATE].copy()
    
#     # ----------------------------------------
#     # 2.2 ×”×’×“×¨×ª ×¢××•×“×•×ª - Data Leakage Safeguard (×“×¨×™×©×” 1)
#     # ----------------------------------------
#     DROP_COLS = ['policy_id', 'date', 'post_event_retention_effort']
#     CATEGORICAL_COLS = ['region'] # 'has_agent' ×• 'is_smoker' ×›×‘×¨ 0/1
#     TARGET_COL = 'lapse_next_3m'
    
#     # ×¢××•×“×•×ª ×”×¤×™×¦'×¨×™× ×©×™×™×©××¨×•
#     FEATURE_COLS = [col for col in df_train.columns if col not in DROP_COLS + [TARGET_COL]]

#     # 2.3 ×¢×™×‘×•×“ ××§×“×™× (One-Hot Encoding ×œ-'region')
#     preprocessor = ColumnTransformer(
#         transformers=[
#             ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), CATEGORICAL_COLS)
#         ],
#         remainder='passthrough'
#     )
    
#     # 2.4 ×”×¤×¨×“×ª X ×•-Y ×•×”×¤×¢×œ×ª ×”-Pipeline
#     def get_X_y(df, preprocessor_obj, fit=False):
#         X_raw = df[FEATURE_COLS]
#         y = df[TARGET_COL]
        
#         if fit:
#             preprocessor_obj.fit(X_raw)
            
#         X_prep = preprocessor_obj.transform(X_raw)
        
#         # ×”××¨×ª ××˜×¨×™×¦×ª NumPy ×‘×—×–×¨×” ×œ-DataFrame ×¢× ×©××•×ª ×¢××•×“×•×ª × ×›×•× ×™×
#         # ×©××•×ª ×”×¤×™×¦'×¨×™× ×©××™× × ×§×˜×’×•×¨×™××œ×™×™×
#         passthrough_cols = [col for col in X_raw.columns if col not in CATEGORICAL_COLS]
#         # ×©××•×ª ×”×¤×™×¦'×¨×™× ×”×—×“×©×™× ×©× ×•×¦×¨×• (××”-OneHot)
#         cat_feature_names = preprocessor_obj.named_transformers_['cat'].get_feature_names_out(CATEGORICAL_COLS)
        
#         feature_names = list(cat_feature_names) + passthrough_cols
        
#         X_df = pd.DataFrame(X_prep, columns=feature_names, index=df.index)
        
#         return X_df, y

#     # ×”×ª×××ª ×”××¢×‘×“ ×”××§×“×™× ×œ-Train
#     X_train_df, y_train = get_X_y(df_train, preprocessor, fit=True)
#     X_val_df, y_val = get_X_y(df_val, preprocessor)
#     X_test_df, y_test = get_X_y(df_test_raw, preprocessor)
    
#     print("\nâœ… Temporal Split and Preprocessing Complete.")
#     print(f"Train set: {len(X_train_df)} rows (End Date: {df_train['date'].max()})")
#     print(f"Validation set: {len(X_val_df)} rows (Period: {df_val['date'].min()} to {df_val['date'].max()})")
#     print(f"Test set: {len(X_test_df)} rows (Start Date: {df_test_raw['date'].min()})")
    
#     # ××—×–×™×¨ ×’× ××ª df_test_raw ×œ×©×™××•×© ×‘-RAG (×›×“×™ ×œ×§×—×ª ×“×•×’×××•×ª ×œ×§×•×—×•×ª)
#     # ğŸš¨ ×ª×™×§×•×Ÿ: ×”×•×¡×¤×ª preprocessor ×œ×¨×©×™××ª ×”××©×ª× ×™× ×”××•×—×–×¨×™× (×›×“×™ ×©×™×”×™×• 8)
#     return X_train_df, y_train, X_val_df, y_val, X_test_df, y_test, df_test_raw, preprocessor

# # ----------------------------------------------------------------------
# # 3. ××™××•×Ÿ, ×›×•×•× ×•×Ÿ ×•×”×¢×¨×›×” (Model_train)
# # ----------------------------------------------------------------------

# def train_and_evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, df_test_raw, preprocessor):
#     """
#     ×›×•×•× ×•×Ÿ ×§×œ ×‘×××¦×¢×•×ª RandomizedSearch ×¢×œ TRAIN ×‘×œ×‘×“ (×¢× TimeSeriesSplit),
#     ××™××•×Ÿ ×¡×•×¤×™ ×¢× early stopping ×¢×œ VAL, ×”×¢×¨×›×” ×¢×œ TEST,
#     ×©××™×¨×ª ××•×“×œ, ×©××™×¨×ª metrics.json ×•×™×¦×™×¨×ª SHAP bar plot.
#     """

#     # ---- 1) ×”×’×“×¨×ª ××•×“×œ ×‘×¡×™×¡×™ ×•×¤×¨××˜×¨×™× ----
#     lgbm = lgb.LGBMClassifier(random_state=SEED, class_weight='balanced', verbose=-1)

#     param_grid = {
#         'n_estimators': [100, 200, 300],
#         'learning_rate': [0.01, 0.05, 0.1],
#         'num_leaves': [15, 31, 63],
#         'max_depth': [3, 5, 7],
#     }

#     # ---- 2) RandomizedSearch: ×”×©×ª××© ×‘-TRAIN ×‘×œ×‘×“ ×¢× TimeSeriesSplit (×“×¨×™×©×” 2) ----
#     print("\nğŸ”¬ Performing Light Tuning (Randomized Search) on TRAIN only...")
#     tscv = TimeSeriesSplit(n_splits=2)
#     search = RandomizedSearchCV(
#         lgbm, param_grid, n_iter=30, scoring='average_precision', # AUC-PR ×›××“×“
#         cv=tscv, random_state=SEED, n_jobs=-1, verbose=0
#     )
#     search.fit(X_train, y_train)
#     best_params = search.best_params_
#     print(f"ğŸ† Best Hyperparameters found (train-only CV): {best_params}")

#     # ---- 3) ××™××•×Ÿ ×¡×•×¤×™ ×¢× Early Stopping ×¢×œ ×¡×˜ ×”-Validation ----
#     final_model = lgb.LGBMClassifier(
#         **best_params, # ğŸš¨ ×ª×™×§×•×Ÿ ×©×’×™××ª ×ª×—×‘×™×¨: ×”×¡×¨×ª ×¤×¡×™×§ ××™×•×ª×¨
#         random_state=SEED,
#         class_weight='balanced',
#         verbose=-1
#     )

#     final_model.fit(
#         X_train, y_train,
#         eval_set=[(X_val, y_val)],
#         eval_metric='average_precision',
#         callbacks=[lgb.early_stopping(stopping_rounds=15, verbose=False)]
#     )

#     # ---- 4) ×”×¢×¨×›×” ×¢×œ Test ----
#     y_test_probas = final_model.predict_proba(X_test)[:, 1]
#     auc_pr = average_precision_score(y_test, y_test_probas)
#     roc_auc = roc_auc_score(y_test, y_test_probas)
#     p_at_1 = calculate_precision_at_k(y_test, y_test_probas, 1)
#     p_at_5 = calculate_precision_at_k(y_test, y_test_probas, 5)

#     metrics = {
#         "AUC-PR": round(auc_pr, 4),
#         "ROC_AUC": round(roc_auc, 4),
#         "Precision@1%": round(p_at_1, 4),
#         "Precision@5%": round(p_at_5, 4)
#     }

#     print("\nğŸ“Š Model Evaluation (Test Set):")
#     print(f"Primary Metric (AUC-PR): {metrics['AUC-PR']:.4f}")
#     print(f"ROC AUC: {metrics['ROC_AUC']:.4f}")
#     print(f"Precision@1%: {metrics['Precision@1%']:.4f}")
#     print(f"Precision@5%: {metrics['Precision@5%']:.4f}")

#     # ---- 5) ×©××™×¨×ª ××•×“×œ ×•××˜×¨×™×§×•×ª ----
#     model_path = os.path.join(OUT_DIR, 'model.pkl')
#     # ×©××™×¨×ª ×”-pipeline ×”××œ× (×›×•×œ×œ preprocessor)
#     full_pipeline = Pipeline([
#         ('preprocessor', preprocessor),
#         ('classifier', final_model)
#     ])
#     joblib.dump(full_pipeline, model_path)
#     print(f"\nğŸ’¾ Model pipeline saved to {model_path}")

#     metrics_path = os.path.join(OUT_DIR, 'metrics.json')
#     with open(metrics_path, 'w') as f:
#         json.dump(metrics, f, indent=4)
#     print(f"ğŸ’¾ Metrics saved to {metrics_path}")

#     # ---- 6) SHAP: ×’×œ×•×‘×œ×™ (bar) ×•×©××™×¨×” ×›-PNG ----
#     try:
#         explainer = shap.TreeExplainer(final_model)
#         shap_values = explainer.shap_values(X_test)
        
#         if isinstance(shap_values, list):
#             shap_for_positive = shap_values[1]
#         else:
#             shap_for_positive = shap_values

#         # ×™×¦×™×¨×ª summary bar plot ×•×©××™×¨×”
#         shap.summary_plot(shap_for_positive, X_test, plot_type="bar", show=False)
#         shap_path = os.path.join(OUT_DIR, 'shap_plot.png')
#         plt.savefig(shap_path, bbox_inches='tight')
#         plt.close()
#         print(f"ğŸ’¾ SHAP Plot saved to {shap_path}")
#     except Exception as e:
#         print(f"âš ï¸ SHAP Plot failed: {e}. (Make sure X_test has non-zero size.)")

#     # ---- 7) ×”×›× ×ª ×˜×¡×˜ ×œ-RAG ----
#     df_test_for_rag = df_test_raw.copy()
#     df_test_for_rag['lapse_proba'] = y_test_probas

#     return full_pipeline, df_test_for_rag, metrics
import pandas as pd
import numpy as np
import os
import json
import joblib
import shap
import lightgbm as lgb
import xgboost as xgb
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit
from sklearn.metrics import average_precision_score, confusion_matrix, roc_auc_score, precision_score
from sklearn.pipeline import Pipeline
from scipy.stats import randint as sp_randint, uniform as sp_uniform

# ----------------------------------------------------------------------
# 0. ×”×’×“×¨×•×ª ×•×§×‘×•×¢×™×
# ----------------------------------------------------------------------

OUT_DIR = 'out'
os.makedirs(OUT_DIR, exist_ok=True)

# ×ª××¨×™×›×™× ×œ×¤×™×¦×•×œ ×–×× ×™
TRAIN_END_DATE = datetime(2023, 9, 1) # ×¢×“ ×¡×¤×˜××‘×¨ (×œ× ×›×•×œ×œ)
VALIDATION_END_DATE = datetime(2023, 10, 1) # ×¡×¤×˜××‘×¨ ×¢×‘×•×¨ Validation, ××•×§×˜×•×‘×¨ ×•×”×œ××” ×œ-Test
SEED = 42 # ×“×˜×¨××™× ×™×–×

# ----------------------------------------------------------------------
# 1. ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ×œ×—×™×©×•×‘ ××˜×¨×™×§×•×ª
# ----------------------------------------------------------------------

def calculate_precision_at_k(y_true, y_probas, k_percent):
    """
    ××—×©×‘ Precision@k (×”×™×¢×™×œ×•×ª ×‘-k% ×”××“×•×¨×’×™× ×¨××©×•× ×™×).
    """
    k = int(len(y_probas) * k_percent / 100)
    if k == 0:
        return 0.0

    df = pd.DataFrame({'proba': y_probas, 'target': y_true})
    df_sorted = df.sort_values(by='proba', ascending=False)
    
    top_k = df_sorted.head(k)
    
    precision = top_k['target'].mean()
    
    return precision

# ----------------------------------------------------------------------
# 2. ×¤×™×¦×•×œ ×–×× ×™ ×•×¢×™×‘×•×“ ××§×“×™×
# ----------------------------------------------------------------------

def perform_temporal_split_and_prep(df_final: pd.DataFrame):
    """
    ××‘×¦×¢ ×¤×™×¦×•×œ ×–×× ×™ ××—××™×¨ ×œ-Train, Validation ×•-Test
    ×•××›×™×Ÿ ××ª ×”× ×ª×•× ×™× ×œ××™××•×Ÿ ×”××•×“×œ.
    """
    
    # 2.1 ×¤×™×¦×•×œ ×–×× ×™ (×“×¨×™×©×” 2: Temporal Integrity)
    df_train = df_final[df_final['date'] < TRAIN_END_DATE].copy()
    df_val_test = df_final[df_final['date'] >= TRAIN_END_DATE].copy()
    df_val = df_val_test[df_val_test['date'] < VALIDATION_END_DATE].copy()
    df_test_raw = df_val_test[df_val_test['date'] >= VALIDATION_END_DATE].copy()
    
    # ----------------------------------------
    # 2.2 ×”×’×“×¨×ª ×¢××•×“×•×ª - Data Leakage Safeguard (×“×¨×™×©×” 1)
    # ----------------------------------------
    DROP_COLS = ['policy_id', 'date', 'post_event_retention_effort']
    CATEGORICAL_COLS = ['region'] # 'has_agent' ×• 'is_smoker' ×›×‘×¨ 0/1
    TARGET_COL = 'lapse_next_3m'
    
    # ×¢××•×“×•×ª ×”×¤×™×¦'×¨×™× ×©×™×™×©××¨×•
    FEATURE_COLS = [col for col in df_train.columns if col not in DROP_COLS + [TARGET_COL]]

    # 2.3 ×¢×™×‘×•×“ ××§×“×™× (One-Hot Encoding ×œ-'region')
    preprocessor = ColumnTransformer(
        transformers=[
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), CATEGORICAL_COLS)
        ],
        remainder='passthrough'
    )
    
    # 2.4 ×”×¤×¨×“×ª X ×•-Y ×•×”×¤×¢×œ×ª ×”-Pipeline
    def get_X_y(df, preprocessor_obj, fit=False):
        X_raw = df[FEATURE_COLS]
        y = df[TARGET_COL]
        
        if fit:
            preprocessor_obj.fit(X_raw)
            
        X_prep = preprocessor_obj.transform(X_raw)
        
        # ×”××¨×ª ××˜×¨×™×¦×ª NumPy ×‘×—×–×¨×” ×œ-DataFrame ×¢× ×©××•×ª ×¢××•×“×•×ª × ×›×•× ×™×
        # ×©××•×ª ×”×¤×™×¦'×¨×™× ×©××™× × ×§×˜×’×•×¨×™××œ×™×™×
        passthrough_cols = [col for col in X_raw.columns if col not in CATEGORICAL_COLS]
        # ×©××•×ª ×”×¤×™×¦'×¨×™× ×”×—×“×©×™× ×©× ×•×¦×¨×• (××”-OneHot)
        cat_feature_names = preprocessor_obj.named_transformers_['cat'].get_feature_names_out(CATEGORICAL_COLS)
        
        feature_names = list(cat_feature_names) + passthrough_cols
        
        X_df = pd.DataFrame(X_prep, columns=feature_names, index=df.index)
        
        return X_df, y

    # ×”×ª×××ª ×”××¢×‘×“ ×”××§×“×™× ×œ-Train
    X_train_df, y_train = get_X_y(df_train, preprocessor, fit=True)
    X_val_df, y_val = get_X_y(df_val, preprocessor)
    X_test_df, y_test = get_X_y(df_test_raw, preprocessor)
    
    print("\nâœ… Temporal Split and Preprocessing Complete.")
    print(f"Train set: {len(X_train_df)} rows (End Date: {df_train['date'].max()})")
    print(f"Validation set: {len(X_val_df)} rows (Period: {df_val['date'].min()} to {df_val['date'].max()})")
    print(f"Test set: {len(X_test_df)} rows (Start Date: {df_test_raw['date'].min()})")
    
    # ××—×–×™×¨ ×’× ××ª df_test_raw ×œ×©×™××•×© ×‘-RAG (×›×“×™ ×œ×§×—×ª ×“×•×’×××•×ª ×œ×§×•×—×•×ª)
    return X_train_df, y_train, X_val_df, y_val, X_test_df, y_test, df_test_raw, preprocessor

# ----------------------------------------------------------------------
# 3. ××™××•×Ÿ, ×›×•×•× ×•×Ÿ ×•×”×¢×¨×›×” (Model_train)
# ----------------------------------------------------------------------


# ×¤×•× ×§×¦×™×” ×—×™×¦×•× ×™×ª ×—×“×©×” ×œ×‘×™×¦×•×¢ ×›×•×•× ×•×Ÿ ×•×”×¢×¨×›×” ×¢×‘×•×¨ ××•×“×œ ×¡×¤×¦×™×¤×™
def tune_and_evaluate_single_model(model_name, X_train, y_train, X_val, y_val, X_test, y_test, preprocessor):
    
    # ×—×™×©×•×‘ ××©×§×œ ×§×œ××¡×™× ×××•×–×Ÿ (×›×“×™ ×œ×ª×ª ××©×§×œ ×œ××™×¢×•×˜ ×”× ×•×˜×©)
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
    
    if model_name == 'LGBM':
        # ×©×™××•×© ×‘-class_weight='balanced'
        model = lgb.LGBMClassifier(random_state=SEED, class_weight='balanced', verbose=-1) 
        param_grid = {
            'n_estimators': sp_randint(100, 400),
            'learning_rate': sp_uniform(0.01, 0.1),
            'num_leaves': sp_randint(15, 63),
            'max_depth': [3, 5, 7, 9],
            'subsample': sp_uniform(0.6, 0.4),
        }
    
    elif model_name == 'XGBoost':
        # ×©×™××•×© ×‘-scale_pos_weight
        model = xgb.XGBClassifier(random_state=SEED, eval_metric='logloss', 
                                  use_label_encoder=False, scale_pos_weight=scale_pos_weight) 
        param_grid = {
            'n_estimators': sp_randint(100, 400),
            'learning_rate': sp_uniform(0.01, 0.1),
            'max_depth': [3, 5, 7, 9],
            'subsample': sp_uniform(0.6, 0.4),
            'colsample_bytree': sp_uniform(0.6, 0.4),
        }
        
    else:
        raise ValueError("Unknown model name")

    # ---- 1) RandomizedSearch ----
    print(f"\nğŸ”¬ Performing Tuning ({model_name}) on TRAIN only...")
    tscv = TimeSeriesSplit(n_splits=3)
    search = RandomizedSearchCV(
        model, param_distributions=param_grid, n_iter=50, 
        scoring='average_precision', cv=tscv, random_state=SEED, n_jobs=-1, verbose=0
    )
    
    # ×§×¨×™××ª ×”-fit ×”×¨××©×•× ×”: *×œ×œ×* fit_params.
    search.fit(X_train, y_train) 
    
    best_params = search.best_params_
    print(f"ğŸ† Best Hyperparameters found ({model_name} CV): {best_params}")

    # ---- 2) ××™××•×Ÿ ×¡×•×¤×™ ×¢× Early Stopping ×¢×œ ×¡×˜ ×”-Validation ----
    
    # ×™×¦×™×¨×ª ××•×“×œ ×—×“×© ×¢× ×”×¤×¨××˜×¨×™× ×”×˜×•×‘×™× ×‘×™×•×ª×¨
    final_model = model.__class__(**best_params, random_state=SEED, verbose=-1) 
    
    # ×™×¦×™×¨×ª fit_params *×¨×§* ×¢×‘×•×¨ final_model.fit
    fit_params = {} 
    
    if model_name == 'LGBM':
        final_model.set_params(class_weight='balanced')
        # ×¤×¨××˜×¨×™× ×¡×¤×¦×™×¤×™×™× ×œ-LGBM (×›××Ÿ ×–×” ×¢×•×‘×“)
        fit_params = {
            'eval_set': [(X_val, y_val)],
            'eval_metric': 'average_precision',
            'callbacks': [lgb.early_stopping(stopping_rounds=20, verbose=False)]
        }
    
    elif model_name == 'XGBoost':
        # ×”×’×“×¨×ª ×¤×¨××˜×¨×™× ×©×”×™×• ×‘××•×“×œ ×”××§×•×¨×™
        final_model.set_params(scale_pos_weight=scale_pos_weight, 
                             eval_metric='logloss',
                             use_label_encoder=False)
        

        
        fit_params = {} # ××©××™×¨×™× ×¨×™×§ ×‘×›×•×•× ×”
        # ------------------------------------------------------------------

    # âš ï¸ ×§×¨×™××ª ×”-fit ×”×©× ×™×™×”: *×¢×* fit_params.
    # ×¢×‘×•×¨ XGBoost, fit_params ×™×”×™×” ×¨×™×§ ×•×–×” ×™×× ×¢ ××ª ×”×©×’×™××”.
    final_model.fit(X_train, y_train, **fit_params)

    # ---- 3) ×”×¢×¨×›×” ×¢×œ Test ----
    y_test_probas = final_model.predict_proba(X_test)[:, 1]
    auc_pr = average_precision_score(y_test, y_test_probas)
    roc_auc = roc_auc_score(y_test, y_test_probas)
    p_at_1 = calculate_precision_at_k(y_test, y_test_probas, 1)
    p_at_5 = calculate_precision_at_k(y_test, y_test_probas, 5)

    metrics = {
        "AUC-PR": round(auc_pr, 4),
        "ROC_AUC": round(roc_auc, 4),
        "Precision@1%": round(p_at_1, 4),
        "Precision@5%": round(p_at_5, 4)
    }
    
    return final_model, metrics, y_test_probas


def train_and_evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, df_test_raw, preprocessor):
    """
    ××‘×¦×¢ ×”×©×•×•××” ×‘×™×Ÿ LGBM ×œ-XGBoost, ×‘×•×—×¨ ××ª ×”××•×“×œ ×”×˜×•×‘ ×‘×™×•×ª×¨ (×œ×¤×™ AUC-PR),
    ×•×©×•××¨ ××ª ×ª×•×¦××•×ª×™×•.
    """
    
    # ---- 1) ×”×©×•×•××” ×‘×™×Ÿ ××•×“×œ×™× ----
    
    # ××™××•×Ÿ ×•×”×¢×¨×›×ª LGBM
    lgbm_model, lgbm_metrics, lgbm_probas = tune_and_evaluate_single_model(
        'LGBM', X_train, y_train, X_val, y_val, X_test, y_test, preprocessor)
    print(f"\nğŸ“Š LGBM Evaluation (Test Set - AUC-PR): {lgbm_metrics['AUC-PR']:.4f}")
    
    # ××™××•×Ÿ ×•×”×¢×¨×›×ª XGBoost
    xgb_model, xgb_metrics, xgb_probas = tune_and_evaluate_single_model(
        'XGBoost', X_train, y_train, X_val, y_val, X_test, y_test, preprocessor)
    print(f"ğŸ“Š XGBoost Evaluation (Test Set - AUC-PR): {xgb_metrics['AUC-PR']:.4f}")
    
    # ---- 2) ×‘×—×™×¨×ª ×”××•×“×œ ×”×× ×¦×— ----
    if lgbm_metrics['AUC-PR'] >= xgb_metrics['AUC-PR']:
        final_model = lgbm_model
        metrics = lgbm_metrics
        y_test_probas = lgbm_probas
        model_type = "LGBMClassifier"
        print(f"\nğŸ† LGBM ({metrics['AUC-PR']:.4f}) is the winner.")
    else:
        final_model = xgb_model
        metrics = xgb_metrics
        y_test_probas = xgb_probas
        model_type = "XGBClassifier"
        print(f"\nğŸ† XGBoost ({metrics['AUC-PR']:.4f}) is the winner.")

    print(f"\nâœ… Final Model Type: {model_type}")
    
    # ×”×¦×’×ª ×”××“×“×™× ×©×œ ×”××•×“×œ ×”× ×‘×—×¨
    print("\nğŸ“Š Final Model Evaluation (Test Set):")
    for key, value in metrics.items():
        print(f"Primary Metric ({key}): {value:.4f}")

    # ---- 3) ×©××™×¨×ª ××•×“×œ ×•××˜×¨×™×§×•×ª ----
    
    # ×™×¦×™×¨×ª Pipeline ×œ×©××™×¨×”
    full_pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', final_model)
    ])
    model_path = os.path.join(OUT_DIR, 'model.pkl')
    joblib.dump(full_pipeline, model_path)
    print(f"\nğŸ’¾ Model pipeline saved to {model_path}")

    metrics_path = os.path.join(OUT_DIR, 'metrics.json')
    with open(metrics_path, 'w') as f:
        json.dump(metrics, f, indent=4)
    print(f"ğŸ’¾ Metrics saved to {metrics_path}")

    # ---- 4) SHAP: ×’×œ×•×‘×œ×™ (bar) ×•×©××™×¨×” ×›-PNG ----
    try:
        explainer = shap.TreeExplainer(final_model)
        shap_values = explainer.shap_values(X_test)
        
        # ×˜×™×¤×•×œ ×‘×¤×•×¨××˜×™× ×©×•× ×™× ×©×œ LGBM / XGBoost
        if isinstance(shap_values, list):
            shap_for_positive = shap_values[1]
        else:
            shap_for_positive = shap_values

        # ×™×¦×™×¨×ª summary bar plot ×•×©××™×¨×”
        plt.figure(figsize=(10, 6))
        shap.summary_plot(shap_for_positive, X_test, plot_type="bar", show=False)
        shap_path = os.path.join(OUT_DIR, 'shap_plot.png')
        plt.savefig(shap_path, bbox_inches='tight')
        plt.close()
        print(f"ğŸ’¾ SHAP Plot saved to {shap_path}")
    except Exception as e:
        print(f"âš ï¸ SHAP Plot failed: {e}. (Make sure X_test has non-zero size.)")

    # ---- 5) ×”×›× ×ª ×˜×¡×˜ ×œ-RAG ----
    df_test_for_rag = df_test_raw.copy()
    df_test_for_rag['lapse_proba'] = y_test_probas

    return full_pipeline, df_test_for_rag, metrics