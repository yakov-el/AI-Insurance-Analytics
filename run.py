#!/usr/bin/env python
# coding: utf-8

# In[1]:


import time
from data_generator import Synth_data_generation
from model_train import perform_temporal_split_and_prep, train_and_evaluate_model
from rag_module import rag_analysis
import json
import os
import pandas as pd # ×•×“× ×©-pandas ××™×•×‘× ×× ××ª×” ××©×ª××© ×‘×¤×•× ×§×¦×™×•×ª ×©×œ×• ×›××Ÿ

# -----------------------------------------------------------
# ×¤×•× ×§×¦×™×™×ª ×”×¨×¦×” ×¨××©×™×ª
# -----------------------------------------------------------
def main():
    """
    ××¨×™×¥ ××ª ×›×œ ×”-Pipeline ×©×œ ×”××˜×œ×”:
    1. ×™×¦×™×¨×ª × ×ª×•× ×™×
    2. ×¤×™×¦×•×œ ×•×¢×™×‘×•×“
    3. ××™××•×Ÿ ××•×“×œ
    4. ×”×¤×¢×œ×ª RAG
    """
    start_time = time.time()

    # -----------------------------------------------------------
    # ×”×’×“×¨×ª ×¡×‘×™×‘×” (×‘×“×™×§×” ×©-API KEY ×§×™×™×)
    # -----------------------------------------------------------
    if not os.environ.get("GEMINI_API_KEY"):
        print("=============================================================")
        print("âš ï¸ ××–×”×¨×”: ××©×ª× ×” ×”×¡×‘×™×‘×” GEMINI_API_KEY ××™× ×• ××•×’×“×¨.")
        print("×©×œ×‘ ×”-RAG (×©×œ×‘ 4) ×™×¨×•×¥, ××š ×™×—×–×™×¨ ×ª×’×•×‘×•×ª ××“×•Ö¼××•Ö¹×ª (mocked LLM responses).")
        print("=============================================================")

    # 1ï¸âƒ£ ×™×¦×™×¨×ª ×“××˜×” ×¡×™× ×ª×˜×™
    print("1ï¸âƒ£ ××ª×—×™×œ ×™×¦×™×¨×ª × ×ª×•× ×™×...")
    df = Synth_data_generation()
    print(f"   × ×•×¦×¨×• {len(df)} ×¨×©×•××•×ª.")

    # 2ï¸âƒ£ ×¤×™×¦×•×œ ×•×¢×™×‘×•×“ × ×ª×•× ×™×
    print("\n2ï¸âƒ£ ××¤×¦×œ ×•××¢×‘×“ × ×ª×•× ×™×...")
    (X_train, y_train, X_val, y_val, 
     X_test, y_test, df_test_raw, preprocessor) = perform_temporal_split_and_prep(df)
    print(f"   ×’×•×“×œ ×¡×˜ ××™××•×Ÿ: {len(X_train)}")

    # 3ï¸âƒ£ ××™××•×Ÿ ××•×“×œ ×•×‘×“×™×§×” (ML Ops)
    print("\n3ï¸âƒ£ ××××Ÿ ×•××¢×¨×™×š ××•×“×œ...")
    model, df_rag, metrics = train_and_evaluate_model(
        X_train, y_train, X_val, y_val, X_test, y_test, df_test_raw, preprocessor
    )
    print(f"   ×”××•×“×œ ××•××Ÿ ×‘×”×¦×œ×—×”. ×¡×•×’ ××•×“×œ: {type(model.named_steps['classifier']).__name__}")

    # ×”×“×¤×¡×ª ××“×“×™ ×”×‘×™×¦×•×¢
    metrics_path = os.path.join('out', 'metrics.json')
    if os.path.exists(metrics_path):
        with open(metrics_path, 'r', encoding='utf-8') as f:
            saved_metrics = json.load(f)
            print("\nâœ… ××“×“×™ ×”××•×“×œ ×”×¡×•×¤×™×™× (××ª×•×š metrics.json):")
            for key, value in saved_metrics.items():
                print(f"   - {key}: {value:.4f}")

    # 4ï¸âƒ£ ×”×¤×¢×œ×ª RAG (×©×œ×™×¤×” ×•×™×¦×™×¨×” ××•×’×‘×¨×ª)
    print("\n4ï¸âƒ£ ××ª×—×™×œ × ×™×ª×•×— RAG (Retrieval Augmented Generation)...")
    rag_output = rag_analysis(df_rag, metrics)

    print("\n--- Pipeline RAG ×”×•×©×œ× ---")
    print("×¤×œ×˜ ×”-RAG × ×©××¨ ×‘-out/rag_output.txt")

    # ×”×“×¤×¡×ª ×¡×™×›×•× ××”×™×¨ ×©×œ ×”×ª×•×›× ×™×ª ×”×¨××©×•× ×”
    first_plan_start = rag_output.find("--- 3-Step Retention Plan ---")
    first_plan_end = rag_output.find("*** Customer Profile: Median Risk")

    if first_plan_start != -1:
        summary_text = rag_output[first_plan_start:first_plan_end if first_plan_end != -1 else len(rag_output)].strip()
        print("\n×¡×™×›×•× ×”×ª×•×›× ×™×ª ×”×¨××©×•× ×” ×©× ×•×¦×¨×” (×œ×§×•×— ×‘×¡×™×›×•×Ÿ ×’×‘×•×”):")
        print(summary_text)

    end_time = time.time()
    total_time = end_time - start_time

    print(f"\nğŸ ×”×ª×”×œ×™×š ×”×¡×ª×™×™× ×‘×”×¦×œ×—×”. ×¡×š ×–××Ÿ ×¨×™×¦×”: {total_time:.2f} ×©× ×™×•×ª.")

# -----------------------------------------------------------
# ×”×¨×¦×ª ×”×¤×•× ×§×¦×™×” ×”×¨××©×™×ª
# -----------------------------------------------------------
if __name__ == "__main__":
    main()


# In[ ]:




